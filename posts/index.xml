<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Making Waves</title><link>https://ctechfilmuniversity.github.io/making-waves/posts/</link><description>Recent content in Posts on Making Waves</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Thu, 30 Jan 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://ctechfilmuniversity.github.io/making-waves/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>Making Waves WS24/25</title><link>https://ctechfilmuniversity.github.io/making-waves/posts/ws2425/</link><pubDate>Thu, 30 Jan 2025 00:00:00 +0000</pubDate><guid>https://ctechfilmuniversity.github.io/making-waves/posts/ws2425/</guid><description>&lt;p>tbd&lt;/p></description><content>&lt;p>tbd&lt;/p></content></item><item><title>Filmuniversity 70 year party</title><link>https://ctechfilmuniversity.github.io/making-waves/posts/70yearparty/</link><pubDate>Tue, 05 Nov 2024 00:00:00 +0000</pubDate><guid>https://ctechfilmuniversity.github.io/making-waves/posts/70yearparty/</guid><description>&lt;p>The 70 year party performance&lt;/p></description><content>&lt;p>The 70 year party performance&lt;/p></content></item><item><title>Making Waves SS24</title><link>https://ctechfilmuniversity.github.io/making-waves/posts/ss24/</link><pubDate>Tue, 30 Jul 2024 00:00:00 +0000</pubDate><guid>https://ctechfilmuniversity.github.io/making-waves/posts/ss24/</guid><description>&lt;p>aka &amp;ldquo;the jam&amp;rdquo;&lt;/p></description><content>&lt;p>aka &amp;ldquo;the jam&amp;rdquo;&lt;/p></content></item><item><title>Making Waves WS23/24</title><link>https://ctechfilmuniversity.github.io/making-waves/posts/ws2324/</link><pubDate>Tue, 30 Jan 2024 00:00:00 +0000</pubDate><guid>https://ctechfilmuniversity.github.io/making-waves/posts/ws2324/</guid><description>&lt;p>consult this repo &lt;a href="https://github.com/ctechfilmuniversity/workshop_ws2324_making_waves">https://github.com/ctechfilmuniversity/workshop_ws2324_making_waves&lt;/a>&lt;/p></description><content>&lt;p>consult this repo &lt;a href="https://github.com/ctechfilmuniversity/workshop_ws2324_making_waves">https://github.com/ctechfilmuniversity/workshop_ws2324_making_waves&lt;/a>&lt;/p></content></item><item><title>Making Waves WS22/23</title><link>https://ctechfilmuniversity.github.io/making-waves/posts/ws2223/</link><pubDate>Mon, 30 Jan 2023 00:00:00 +0000</pubDate><guid>https://ctechfilmuniversity.github.io/making-waves/posts/ws2223/</guid><description>&lt;p>The Making Waves workshop series aimed to introduce students to generative compositional techniques in the context of live performance. Each session began with a brief theoretical introduction, followed by practical demonstrations and an open session for students to apply what they had learned to their final performance.&lt;/p>
&lt;p>During the final performances, students from diverse backgrounds had the opportunity to showcase their existing work, collaborate on a unified audio-visual piece, or perform their own 15-minute live set. The open workshop format allowed students to design their individual setups based on their unique artistic goals and needs, while also giving the workshop room to grow and refine its focus over time.&lt;/p></description><content>&lt;p>The Making Waves workshop series aimed to introduce students to generative compositional techniques in the context of live performance. Each session began with a brief theoretical introduction, followed by practical demonstrations and an open session for students to apply what they had learned to their final performance.&lt;/p>
&lt;p>During the final performances, students from diverse backgrounds had the opportunity to showcase their existing work, collaborate on a unified audio-visual piece, or perform their own 15-minute live set. The open workshop format allowed students to design their individual setups based on their unique artistic goals and needs, while also giving the workshop room to grow and refine its focus over time.&lt;/p>
&lt;p>The recordings of the final performances can be found &lt;a href="https://github.com/Myxxin/Making-Waves-Retrospective/tree/main/final_recordings">here&lt;/a>.&lt;/p>
&lt;h2 id="session-one---inspiration-and-exploration">Session One - Inspiration and Exploration&lt;/h2>
&lt;p>The first session of the workshop aimed to provide visual inspiration and an overview of the available musical tools to the students. After introducing the concept of generative algorithms and their ability to create data similar to existing data, the students were given local installations of the Stable Diffusion image generation AI. They explored the power of this particular generative model and created potential mood boards for their future performances&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/93442123/224561542-e3ef4463-69a9-483f-ad23-7ce9c8712c5c.png" alt="cat">
&lt;img src="https://user-images.githubusercontent.com/93442123/224561546-b6167e73-9c9a-4118-99b0-a79ea5851d74.png" alt="king crimson">
&lt;img src="https://user-images.githubusercontent.com/93442123/224561549-88358dda-2e81-474f-9d20-40931f1ab7c4.png" alt="steampunk-flower">&lt;/p>
&lt;p>However, the technical introduction to the inner workings of AI went over the heads of most students, including the creative technologists. As a result, AI was not further utilized in the course.&lt;/p>
&lt;p>During the second half of the workshop, the students had the opportunity to explore the musical devices of the Creative Technologies program with the guidance of the lecturers. This part of the session was well-received and included the following devices:&lt;/p>
&lt;ul>
&lt;li>MPC LIVE II&lt;/li>
&lt;li>Elektron Digitone&lt;/li>
&lt;li>Roland MC 707&lt;/li>
&lt;li>Multiple Korg Volcas&lt;/li>
&lt;li>Synthstrom Deluge&lt;/li>
&lt;li>Korg Minilogue&lt;/li>
&lt;li>Critter &amp;amp; Guitari Organelle&lt;/li>
&lt;/ul>
&lt;h2 id="session-two---sound-synthesis">Session Two - Sound Synthesis&lt;/h2>
&lt;p>The second session of the workshop aimed to provide the students with a solid understanding of sound synthesis fundamentals while also encouraging them to experiment with more left-field methods. Marco Winter gave the first presentation, which largely focused on subtractive and demonstrated with the &lt;a href="https://www.ableton.com/de/packs/wavetable/">Ableton Wavetable synthesizer&lt;/a>.&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/93442123/224562024-4d1ccd50-3faa-447f-bcfe-b1d0d39f23c3.jpg" alt="synthesis">&lt;/p>
&lt;p>Lara&amp;rsquo;s presentation focused on her own work, influences, and techniques. She took a different approach, highlighting granular synthesis using orchestral samples as an alternative and more explorative way of creating sounds.&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/93442123/224565359-320e0252-161d-4058-bc26-e747a61eb141.JPG" alt="lara">&lt;/p>
&lt;h2 id="session-three---resolume">Session Three - Resolume&lt;/h2>
&lt;p>The third session took a break from the music-focused sessions and shifted the focus to creating visuals to complement the final performances. The students presented songs that inspire them and created a shared playlist to get to know each other better, which can be accessed here: &lt;a href="https://open.spotify.com/playlist/7loq1NhkBNZHofEJ2ye6yU?si=9ad230fdd12c4b2c">shared playlist&lt;/a>.&lt;/p>
&lt;p>After the warmup, Rita introduced the class to the powerful VJing software, Resolume.&lt;/p>
&lt;h2 id="session-four---generative-techniques-in-ableton-live-and-max-for-live">Session Four - Generative Techniques in Ableton Live and Max for Live&lt;/h2>
&lt;p>Session four delved deeper into the generative capabilities of Ableton Live and Max Msp/Max for Live. The first part of the session focused on generative techniques built into Ableton Live, such as following action, midi probability, and LFO-driven sound design.&lt;/p>
&lt;p>&lt;a href="https://user-images.githubusercontent.com/93442123/224732877-46b6915d-66b8-4d4c-b651-21a01075251e.MP4">https://user-images.githubusercontent.com/93442123/224732877-46b6915d-66b8-4d4c-b651-21a01075251e.MP4&lt;/a>&lt;/p>
&lt;p>In the second part of the theoretical session, Justin Robinson led a presentation on his generative instrument, Pärtinator, and provided an overview of the Max MSP visual programming environment.&lt;/p>
&lt;h2 id="final-performances">Final Performances&lt;/h2>
&lt;h2 id="andreea-jonathan--enrique">Andreea, Jonathan &amp;amp; Enrique&lt;/h2>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/93442123/225284679-77fa05ce-b10b-44f8-9349-a30f9e23ef38.JPG" alt="Folie1">&lt;/p>
&lt;p>&lt;a href="https://user-images.githubusercontent.com/93442123/224740964-1b4b6efb-0295-4a78-b2b8-f2d96ba3a3f3.mp4">https://user-images.githubusercontent.com/93442123/224740964-1b4b6efb-0295-4a78-b2b8-f2d96ba3a3f3.mp4&lt;/a>&lt;/p>
&lt;p>Andreea, Jonathan, and Enrique combined their favorite techniques and tools from the workshop with their own recordings and live vocals to create a shared hybrid setup. They began with a set of self-recorded piano samples and processed them using Ableton Live and its Simpler instrument by slicing, reversing, and other effects. As the tune progressed, the piano sound was backed rhythmically by drums, bass, and a heartbeat sample. To play back their prepared clips during the performance, they used a Launchpad.&lt;/p>
&lt;p>The Synthstrom Deluge played the prominent brassy synth tone, which was routed into Ableton Live. Andreea&amp;rsquo;s vocals were the guiding force throughout the song, picked up by two microphones. The first was mixed with generous reverb and delay in Ableton Live, while the second was routed to a second computer. The lyrics, generated by the ChatGPT text generation AI, were about &amp;ldquo;making waves&amp;rdquo; and matched the visuals perfectly.&lt;/p>
&lt;p>&lt;a href="https://user-images.githubusercontent.com/93442123/225325434-869cfcbe-e148-42ac-a31f-465a24ecec82.MOV">https://user-images.githubusercontent.com/93442123/225325434-869cfcbe-e148-42ac-a31f-465a24ecec82.MOV&lt;/a>&lt;/p>
&lt;p>The group prepared three layers of visuals using Resolume: abstract and realistic stock footage, and their own wave-like line animations created in Procreate. They would switch and blend between these layers during the performance, using the volume of the second microphone to control additional effects such as scaling or mirroring.&lt;/p>
&lt;p>However, reflecting on their performance, the setup proved to be too complicated. Their computers struggled with the workload, and all the different tools were challenging to handle simultaneously. For their next performance, they streamlined their setup significantly with the help of a hardware mixer. Looking back, they realized that an additional workshop day to prepare for the live performance would have been tremendously helpful in addressing these issues.&lt;/p>
&lt;h2 id="marco">Marco&lt;/h2>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/93442123/224735932-975650eb-c54f-4ad8-b3ba-7dee26a00295.PNG" alt="Folie1">&lt;/p>
&lt;p>&lt;a href="https://user-images.githubusercontent.com/93442123/223133333-6ec67e04-13e3-4808-8038-8fb97e67b1bb.mp4">https://user-images.githubusercontent.com/93442123/223133333-6ec67e04-13e3-4808-8038-8fb97e67b1bb.mp4&lt;/a>&lt;/p>
&lt;p>For my performance, I opted for a dawless setup comprising of an Elektron Syntakt 12 track mono-synth and a Digitone FM 4 track poly-synth. I routed the Digitone into the Syntakt&amp;rsquo;s inputs to benefit from its analog fx track and also to smoothly bring in a new track with the digitone master gain.&lt;/p>
&lt;p>Both devices&amp;rsquo; data structure can be categorized as Project&amp;gt;Songs&amp;gt;Patterns&amp;gt;Tracks&amp;gt;Sounds. With the recent addition of song mode, I could conveniently queue songs/patterns and switch between pre-recorded sequences, achieving the desired balance between structure and improvisation. However, at present, it&amp;rsquo;s not possible to pre-assign which patterns should play in loop mode by default (each pattern plays for a specific number of loops). So, if a pattern needs to loop for a while, it demands good coordination across both devices.&lt;/p>
&lt;p>I was very pleased with this setup&amp;rsquo;s sound quality - I designed every sound from scratch for the first time. However, except for the short intro, the songs didn&amp;rsquo;t entirely resonate with me, so I plan to streamline things further. My next objective is to integrate both devices into a Daw environment using the Overbridge VST. This way, I can use Ableton Live as a mixer to refine the sound, play samples, and experiment with various FX techniques.&lt;/p>
&lt;h2 id="stefan">Stefan&lt;/h2>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/93442123/224736378-0a3fbd59-9149-4963-9200-3c2ee2709d29.PNG" alt="Folie1">&lt;/p>
&lt;p>&lt;a href="https://user-images.githubusercontent.com/93442123/224733261-28c2e2a3-7702-46ef-a7cd-93ad7e551322.mp4">https://user-images.githubusercontent.com/93442123/224733261-28c2e2a3-7702-46ef-a7cd-93ad7e551322.mp4&lt;/a>&lt;/p>
&lt;p>For his setup Stefan Püst, went dawless as well, connecting his Roland MC 707 to his Octatrack.
He utilized the MC 707 to combine multiple prerecorded instrument loops and create full arrangements. By muting, fading in/out, and swapping individual loops, he constructed an overarching structure for his performance. Additionally, he used the Octatrack to play prepared transition effects, with the patterns containing effects automations like filter sweeps. Stefan relied on the A/B fader of the Octatrack as a Dry/Wet control to switch to the effect-mangled version of his track at the appropriate moment.&lt;/p></content></item></channel></rss>